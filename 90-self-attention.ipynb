{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(23)\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 4\n",
    "d_ff = 4\n",
    "d_k = 3\n",
    "d_v = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_ = np.random.randn(d_model)\n",
    "gusta_ = np.random.randn(d_model)\n",
    "estudiar_ = np.random.randn(d_model)\n",
    "inteligencia_ = np.random.randn(d_model)\n",
    "artificial_ = np.random.randn(d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.667   0.0258 -0.7776  0.9486]\n"
     ]
    }
   ],
   "source": [
    "print(me_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_1 = np.array([0.3, -0.9, -0.6, 0.8])\n",
    "pos_2 = np.array([-0.6, 0.8, -0.9, 0.15])\n",
    "pos_3 = np.array([0.8, -0.5, -0.9, 0.5])\n",
    "pos_4 = np.array([-0.9, 0.2, -0.4, -0.9])\n",
    "pos_5 = np.array([0.95, 0.16, 0.2, -0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.967  -0.8742 -1.3776  1.7486]\n"
     ]
    }
   ],
   "source": [
    "me_embed_pos = me_ + pos_1\n",
    "gusta_embed_pos = gusta_ + pos_2\n",
    "estudiar_embed_pos = estudiar_ + pos_3\n",
    "inteligencia_embed_pos = inteligencia_ + pos_4\n",
    "artificial_embed_pos = artificial_ + pos_5\n",
    "print(me_embed_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection matrix (or FC network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_q = np.random.randn(d_model, d_k) * 0.1\n",
    "W_k = np.random.randn(d_model, d_k) * 0.1\n",
    "W_v = np.random.randn(d_model, d_v) * 0.1\n",
    "\n",
    "me_query = me_embed_pos @ W_q\n",
    "me_key = me_embed_pos @ W_k\n",
    "me_value = me_embed_pos @ W_v\n",
    "\n",
    "gusta_query = gusta_embed_pos @ W_q\n",
    "gusta_key = gusta_embed_pos @ W_k\n",
    "gusta_value = gusta_embed_pos @ W_v\n",
    "\n",
    "estudiar_query = estudiar_embed_pos @ W_q\n",
    "estudiar_key = estudiar_embed_pos @ W_k\n",
    "estudiar_value = estudiar_embed_pos @ W_v\n",
    "\n",
    "inteligencia_query = inteligencia_embed_pos @ W_q\n",
    "inteligencia_key = inteligencia_embed_pos @ W_k\n",
    "inteligencia_value = inteligencia_embed_pos @ W_v\n",
    "\n",
    "artificial_query = artificial_embed_pos @ W_q\n",
    "artificial_key = artificial_embed_pos @ W_k\n",
    "artificial_value = artificial_embed_pos @ W_v\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "  x -= np.max(x, axis=1, keepdims=True)\n",
    "  return np.exp(x)/np.exp(x).sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palabra me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me_query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1984 0.203  0.1929 0.2045 0.2012]]\n"
     ]
    }
   ],
   "source": [
    "me_alpha_me = me_query @ me_key.T\n",
    "me_alpha_gusta = me_query @ gusta_key.T\n",
    "me_alpha_estudiar = me_query @ estudiar_key.T\n",
    "me_alpha_inteligencia = me_query @ inteligencia_key.T\n",
    "me_alpha_artificial = me_query @ artificial_key.T\n",
    "\n",
    "me_alphas = softmax(([[me_alpha_me, me_alpha_gusta, me_alpha_estudiar, me_alpha_inteligencia, me_alpha_artificial]]))\n",
    "print(me_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1984])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me_alphas[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_attention = np.array([\n",
    "    me_alphas[:,0] * me_value + \n",
    "    me_alphas[:,1] * gusta_value +\n",
    "    me_alphas[:,2] * estudiar_value +\n",
    "    me_alphas[:,3] * inteligencia_value +\n",
    "    me_alphas[:,4] * artificial_value\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0066 -0.0286  0.0036]]\n"
     ]
    }
   ],
   "source": [
    "print(me_attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palabra gusta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alphas de gusta: [[0.177  0.194  0.2195 0.2076 0.2019]]\n",
      "atencion de gusta: [[ 0.0062 -0.0306 -0.0024]]\n"
     ]
    }
   ],
   "source": [
    "gusta_alpha_me = gusta_query @ me_key.T\n",
    "gusta_alpha_gusta = gusta_query @ gusta_key.T\n",
    "gusta_alpha_estudiar = gusta_query @ estudiar_key.T\n",
    "gusta_alpha_inteligencia = gusta_query @ inteligencia_key.T\n",
    "gusta_alpha_artificial = gusta_query @ artificial_key.T\n",
    "gusta_alphas = softmax(([[gusta_alpha_me, gusta_alpha_gusta, gusta_alpha_estudiar, gusta_alpha_inteligencia, gusta_alpha_artificial]]))\n",
    "print(\"alphas de gusta:\", gusta_alphas)\n",
    "gusta_attention = np.array([\n",
    "    gusta_alphas[:,0] * me_value + \n",
    "    gusta_alphas[:,1] * gusta_value +\n",
    "    gusta_alphas[:,2] * estudiar_value +\n",
    "    gusta_alphas[:,3] * inteligencia_value +\n",
    "    gusta_alphas[:,4] * artificial_value\n",
    "])\n",
    "print(\"atencion de gusta:\", gusta_attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Palabra estudiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alphas de estudiar: [[0.1967 0.2003 0.1981 0.2016 0.2032]]\n",
      "atencion de estudiar: [[ 0.0066 -0.0293  0.0018]]\n"
     ]
    }
   ],
   "source": [
    "estudiar_alpha_me = estudiar_query @ me_key.T\n",
    "estudiar_alpha_gusta = estudiar_query @ gusta_key.T\n",
    "estudiar_alpha_estudiar = estudiar_query @ estudiar_key.T\n",
    "estudiar_alpha_inteligencia = estudiar_query @ inteligencia_key.T\n",
    "estudiar_alpha_artificial = estudiar_query @ artificial_key.T\n",
    "\n",
    "estudiar_alphas = softmax(([[estudiar_alpha_me, estudiar_alpha_gusta, estudiar_alpha_estudiar, estudiar_alpha_inteligencia, estudiar_alpha_artificial]]))\n",
    "print(\"alphas de estudiar:\", estudiar_alphas)\n",
    "estudiar_attention = np.array([\n",
    "    estudiar_alphas[:,0] * me_value + \n",
    "    estudiar_alphas[:,1] * gusta_value +\n",
    "    estudiar_alphas[:,2] * estudiar_value +\n",
    "    estudiar_alphas[:,3] * inteligencia_value +\n",
    "    estudiar_alphas[:,4] * artificial_value\n",
    "])\n",
    "print(\"atencion de estudiar:\", estudiar_attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palabra inteligencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alphas de inteligencia: [[0.1662 0.1897 0.2319 0.2095 0.2027]]\n",
      "atencion de inteligencia: [[ 0.006  -0.0315 -0.0049]]\n"
     ]
    }
   ],
   "source": [
    "inteligencia_alpha_me = inteligencia_query @ me_key.T\n",
    "inteligencia_alpha_gusta = inteligencia_query @ gusta_key.T\n",
    "inteligencia_alpha_estudiar = inteligencia_query @ estudiar_key.T\n",
    "inteligencia_alpha_inteligencia = inteligencia_query @ inteligencia_key.T\n",
    "inteligencia_alpha_artificial = inteligencia_query @ artificial_key.T\n",
    "inteligencia_alphas = softmax(([[inteligencia_alpha_me, inteligencia_alpha_gusta, inteligencia_alpha_estudiar, inteligencia_alpha_inteligencia, inteligencia_alpha_artificial]]))\n",
    "print(\"alphas de inteligencia:\", inteligencia_alphas)\n",
    "inteligencia_attention = np.array([\n",
    "    inteligencia_alphas[:,0] * me_value + \n",
    "    inteligencia_alphas[:,1] * gusta_value +\n",
    "    inteligencia_alphas[:,2] * estudiar_value +\n",
    "    inteligencia_alphas[:,3] * inteligencia_value +\n",
    "    inteligencia_alphas[:,4] * artificial_value\n",
    "])\n",
    "print(\"atencion de inteligencia:\", inteligencia_attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palabra artificial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alphas de artificial: [[0.1894 0.1939 0.2182 0.1996 0.199 ]]\n",
      "atencion de artificial: [[ 0.0068 -0.0313 -0.0067]]\n"
     ]
    }
   ],
   "source": [
    "artificial_alpha_me = artificial_query @ me_key.T\n",
    "artificial_alpha_gusta = artificial_query @ gusta_key.T\n",
    "artificial_alpha_estudiar = artificial_query @ estudiar_key.T\n",
    "artificial_alpha_inteligencia = artificial_query @ inteligencia_key.T\n",
    "artificial_alpha_artificial = artificial_query @ artificial_key.T\n",
    "artificial_alphas = softmax(([[artificial_alpha_me, artificial_alpha_gusta, artificial_alpha_estudiar, artificial_alpha_inteligencia, artificial_alpha_artificial]]))   \n",
    "print(\"alphas de artificial:\", artificial_alphas)\n",
    "artificial_attention = np.array([\n",
    "    artificial_alphas[:,0] * me_value + \n",
    "    artificial_alphas[:,1] * gusta_value +\n",
    "    artificial_alphas[:,2] * estudiar_value +\n",
    "    artificial_alphas[:,3] * inteligencia_value +\n",
    "    artificial_alphas[:,4] * artificial_value\n",
    "])\n",
    "print(\"atencion de artificial:\", artificial_attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [[ 0.967  -0.8742 -1.3776  1.7486]\n",
      " [ 0.1017 -0.2511 -1.2675 -0.9875]\n",
      " [-0.5221  1.2723 -1.2475  1.1701]\n",
      " [-0.5777  0.2603 -1.4435 -1.9099]\n",
      " [ 1.3917  1.2889 -1.6381 -1.8888]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[me_embed_pos], [gusta_embed_pos], [estudiar_embed_pos], [inteligencia_embed_pos], [artificial_embed_pos]]).reshape(-1, d_model)\n",
    "print(\"X:\", X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = X @ W_q\n",
    "K = X @ W_k\n",
    "V = X @ W_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: [[-0.2856  0.1529  0.1914]\n",
      " [ 0.1156 -0.2958 -0.0378]\n",
      " [-0.0123 -0.0164 -0.1174]\n",
      " [ 0.2861 -0.5074 -0.1684]\n",
      " [ 0.3299 -0.2983 -0.1628]]\n",
      "K: [[ 0.21    0.4861  0.0043]\n",
      " [-0.1448  0.0443 -0.0516]\n",
      " [-0.0906 -0.3696  0.0938]\n",
      " [-0.3261 -0.2561 -0.0451]\n",
      " [-0.2622 -0.1248 -0.1372]]\n",
      "V: [[ 0.041  -0.0518 -0.2071]\n",
      " [ 0.004   0.0187  0.1207]\n",
      " [ 0.0223 -0.1137 -0.3795]\n",
      " [-0.006   0.0276  0.1633]\n",
      " [-0.0271 -0.0291  0.2981]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Q:\", Q)\n",
    "print(\"K:\", K)\n",
    "print(\"V:\", V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.2856  0.1529  0.1914]\n",
      "[ 0.1156 -0.2958 -0.0378]\n",
      "[-0.0123 -0.0164 -0.1174]\n",
      "[ 0.2861 -0.5074 -0.1684]\n",
      "[ 0.3299 -0.2983 -0.1628]\n"
     ]
    }
   ],
   "source": [
    "print(me_query)\n",
    "print(gusta_query)\n",
    "print(estudiar_query)\n",
    "print(inteligencia_query)\n",
    "print(artificial_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3)\n"
     ]
    }
   ],
   "source": [
    "print(Q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3)\n"
     ]
    }
   ],
   "source": [
    "print(K.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alphas: [[0.1984 0.203  0.1929 0.2045 0.2012]\n",
      " [0.177  0.194  0.2195 0.2076 0.2019]\n",
      " [0.1967 0.2003 0.1981 0.2016 0.2032]\n",
      " [0.1662 0.1897 0.2319 0.2095 0.2027]\n",
      " [0.1894 0.1939 0.2182 0.1996 0.199 ]]\n"
     ]
    }
   ],
   "source": [
    "alphas = softmax(Q @ K.T)\n",
    "print(\"alphas:\", alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atencion scores: [[ 0.0066 -0.0286  0.0036]\n",
      " [ 0.0062 -0.0306 -0.0024]\n",
      " [ 0.0066 -0.0293  0.0018]\n",
      " [ 0.006  -0.0315 -0.0049]\n",
      " [ 0.0068 -0.0313 -0.0067]]\n"
     ]
    }
   ],
   "source": [
    "attention_scores = alphas @ V\n",
    "print(\"atencion scores:\", attention_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entornoJupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
