{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ h_{out} = \\frac{1}{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolucional Neuronal Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/juangomez/Desktop/ML/Cursos/Pepe Cantoral/datasets'\n",
    "num_train = 50000\n",
    "num_val = 5000\n",
    "num_test = 5000\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "transform_cifar = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.491, 0.482, 0.447], [0.247, 0.243, 0.261])\n",
    "])\n",
    "\n",
    "# Training set\n",
    "cifar10_train = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_cifar)\n",
    "train_loader = DataLoader(\n",
    "    cifar10_train,\n",
    "    batch_size=batch_size,\n",
    "    sampler=sampler.SubsetRandomSampler(range(num_train)))\n",
    "\n",
    "# Validation set\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train= False,\n",
    "    download=True,\n",
    "    transform=transform_cifar)\n",
    "val_loader = DataLoader(\n",
    "    cifar10_val,\n",
    "    batch_size=batch_size,\n",
    "    sampler=sampler.SubsetRandomSampler(range(num_val)))\n",
    "\n",
    "# Test set\n",
    "cifar10_test = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform= transform_cifar)\n",
    "test_loader = DataLoader(\n",
    "    cifar10_test,\n",
    "    batch_size=batch_size,\n",
    "    sampler=sampler.SubsetRandomSampler(range(num_test, num_test + num_val))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# this make a generator\n",
    "data_iter = iter(train_loader)\n",
    "# get the first batch\n",
    "images, labels = next(data_iter)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show the image 0 of the batch 0. Class: \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = ['Plane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "\n",
    "def plot_figure(image):\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "idx= np.random.randint(len(test_loader))\n",
    "print(f'Show the image 0 of the batch {idx}. Class: ')\n",
    "image = test_loader.dataset[idx][0]\n",
    "image = (image- image.min())/(image.max()-image.min())\n",
    "plot_figure(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, loader):\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for xi, yi in loader:\n",
    "            xi = xi.to(device)\n",
    "            yi = yi.to(device)\n",
    "            scores = model(xi)\n",
    "            # Compute the max in each row for each image of the batch\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == yi).sum()\n",
    "            num_total += len(yi)\n",
    "        return float(num_correct) / num_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs=100):\n",
    "    model = model.to(device = device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for (xi, yi) in train_loader:\n",
    "            xi = xi.to(device = device, dtype=torch.float32)\n",
    "            yi = yi.to(device = device, dtype=torch.long)\n",
    "            scores = model(xi)\n",
    "\n",
    "            cost = F.cross_entropy(input=scores, target=yi.squeeze())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "        acc = accuracy(model, val_loader)\n",
    "        if epoch%1 == 0:\n",
    "            print(f'Epoch {epoch}, Cost: {cost.item()}, accuracy: {acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secuential linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cost: 1.438110113143921, accuracy: 0.4424\n",
      "Epoch 1, Cost: 1.1234761476516724, accuracy: 0.4846\n",
      "Epoch 2, Cost: 1.485788106918335, accuracy: 0.5054\n",
      "Epoch 3, Cost: 1.3838521242141724, accuracy: 0.5028\n",
      "Epoch 4, Cost: 1.1389840841293335, accuracy: 0.5186\n",
      "Epoch 5, Cost: 0.9106072783470154, accuracy: 0.5232\n",
      "Epoch 6, Cost: 0.6873882412910461, accuracy: 0.5266\n",
      "Epoch 7, Cost: 1.3991081714630127, accuracy: 0.5322\n",
      "Epoch 8, Cost: 1.2146023511886597, accuracy: 0.522\n",
      "Epoch 9, Cost: 1.295867681503296, accuracy: 0.518\n"
     ]
    }
   ],
   "source": [
    "hidden1 = 256\n",
    "hidden2 = 256\n",
    "lr = 1e-3\n",
    "epochs = 10\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features = 3*32*32, out_features=hidden1), nn.ReLU(),\n",
    "    nn.Linear(in_features = hidden1, out_features=hidden2), nn.ReLU(),\n",
    "    nn.Linear(in_features = hidden2, out_features=10), nn.ReLU()\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas= (0.9, 0.999))\n",
    "train(model, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequetial CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cost: 0.9675833582878113, accuracy: 0.6236\n",
      "Epoch 1, Cost: 1.0232064723968506, accuracy: 0.6362\n",
      "Epoch 2, Cost: 0.8187881708145142, accuracy: 0.6734\n",
      "Epoch 3, Cost: 1.1195194721221924, accuracy: 0.673\n",
      "Epoch 4, Cost: 0.7572863101959229, accuracy: 0.6772\n",
      "Epoch 5, Cost: 0.5643727779388428, accuracy: 0.6778\n",
      "Epoch 6, Cost: 0.6526426672935486, accuracy: 0.6714\n",
      "Epoch 7, Cost: 0.9975497126579285, accuracy: 0.6636\n",
      "Epoch 8, Cost: 0.4249037802219391, accuracy: 0.6628\n",
      "Epoch 9, Cost: 0.33954930305480957, accuracy: 0.6562\n"
     ]
    }
   ],
   "source": [
    "channel1 = 16\n",
    "channel2 = 32\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "\n",
    "modelCNN1 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=channel1, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=channel1, out_channels=channel2, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=16*16*channel2, out_features=10)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(modelCNN1.parameters(), lr=lr, betas= (0.9, 0.999))\n",
    "train(modelCNN1, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test: 0.6538\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(modelCNN1, test_loader)\n",
    "print(f'Accuracy test: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_class1(nn.Module):\n",
    "    def __init__(self, in_channels, channel1, channel2):\n",
    "        super(CNN_class1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=channel1, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=channel1, out_channels=channel2, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(in_features=16*16*channel2, out_features=10)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cost: 0.6411479711532593, accuracy: 0.636\n",
      "Epoch 1, Cost: 0.886730968952179, accuracy: 0.6596\n",
      "Epoch 2, Cost: 1.0214401483535767, accuracy: 0.6778\n",
      "Epoch 3, Cost: 1.1733015775680542, accuracy: 0.6832\n",
      "Epoch 4, Cost: 0.7102988362312317, accuracy: 0.6844\n",
      "Epoch 5, Cost: 0.6249756813049316, accuracy: 0.6774\n",
      "Epoch 6, Cost: 0.29727068543434143, accuracy: 0.683\n",
      "Epoch 7, Cost: 0.706306517124176, accuracy: 0.6658\n",
      "Epoch 8, Cost: 0.5570478439331055, accuracy: 0.6604\n",
      "Epoch 9, Cost: 0.6709380745887756, accuracy: 0.6688\n"
     ]
    }
   ],
   "source": [
    "channel1 = 16\n",
    "channel2 = 32\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "\n",
    "modelCNN2 = CNN_class1(in_channels=3, channel1=channel1, channel2=channel2)\n",
    "optimizer = torch.optim.Adam(modelCNN2.parameters(), lr=lr, betas= (0.9, 0.999))\n",
    "train(modelCNN2, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test: 0.6564\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(modelCNN2, test_loader)\n",
    "print(f'Accuracy test: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A little more elegant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_k_3 = lambda channel1, channel2: nn.Conv2d(in_channels=channel1, out_channels=channel2, kernel_size=3, stride=1, padding=1)\n",
    "class CNN_class1(nn.Module):\n",
    "    def __init__(self, in_channels, channel1, channel2):\n",
    "        super(CNN_class1, self).__init__()\n",
    "        self.conv1 = conv_k_3(in_channels=in_channels, out_channels=channel1)\n",
    "        self.conv2 = conv_k_3(in_channels=channel1, out_channels=channel2)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(in_features=16*16*channel2, out_features=10)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entornoJupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
